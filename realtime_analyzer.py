#!/usr/bin/env python3
# realtime_analyzer.py

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from github import Github
import os
from datetime import datetime, timedelta
import asyncio
import concurrent.futures
import time
from typing import Dict, List, Optional
import json
import re
from collections import Counter
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealtimeGitHubAnalyzer:
    def __init__(self, github_token: str):
        """ì‹¤ì‹œê°„ GitHub ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.github = Github(github_token)
        self.rate_limit_buffer = 100  # API ì†ë„ ì œí•œ ë²„í¼
    
    def search_repositories(self, query: str, language: str = None, 
                          min_stars: int = 0, max_results: int = 10) -> List[Dict]:
        """ì €ì¥ì†Œ ê²€ìƒ‰"""
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            search_query = f"{query}"
            if language:
                search_query += f" language:{language}"
            if min_stars > 0:
                search_query += f" stars:>={min_stars}"
            
            # ê²€ìƒ‰ ì‹¤í–‰
            repositories = self.github.search_repositories(
                query=search_query,
                sort="stars",
                order="desc"
            )
            
            # ê²°ê³¼ íŒŒì‹±
            results = []
            for i, repo in enumerate(repositories):
                if i >= max_results:
                    break
                
                results.append({
                    'name': repo.name,
                    'full_name': repo.full_name,
                    'description': repo.description or "ì„¤ëª… ì—†ìŒ",
                    'stars': repo.stargazers_count,
                    'forks': repo.forks_count,
                    'language': repo.language or "Unknown",
                    'created_at': repo.created_at,
                    'updated_at': repo.updated_at,
                    'url': repo.html_url
                })
            
            return results
        
        except Exception as e:
            logger.error(f"ì €ì¥ì†Œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def quick_analyze_repository(self, repo_name: str, days_back: int = 30) -> Dict:
        """ì €ì¥ì†Œ ë¹ ë¥¸ ë¶„ì„"""
        try:
            repo = self.github.get_repo(repo_name)
            since_date = datetime.now() - timedelta(days=days_back)
            
            # ê¸°ë³¸ ì •ë³´
            analysis = {
                'repo_info': {
                    'name': repo.name,
                    'full_name': repo.full_name,
                    'description': repo.description,
                    'stars': repo.stargazers_count,
                    'forks': repo.forks_count,
                    'language': repo.language,
                    'created_at': repo.created_at,
                    'updated_at': repo.updated_at,
                    'open_issues': repo.open_issues_count,
                    'size': repo.size
                },
                'recent_activity': {},
                'contributors': {},
                'languages': {},
                'commit_patterns': {}
            }
            
            # ìµœê·¼ ì»¤ë°‹ ë¶„ì„ (ë¹ ë¥¸ ë¶„ì„ì„ ìœ„í•´ ìµœëŒ€ 100ê°œ)
            commits = list(repo.get_commits(since=since_date)[:100])
            
            if commits:
                # ì»¤ë°‹ í†µê³„
                commit_data = []
                authors = []
                commit_times = []
                
                for commit in commits:
                    if commit.author:
                        authors.append(commit.author.login)
                    if commit.commit.author:
                        commit_times.append(commit.commit.author.date)
                    
                    commit_data.append({
                        'author': commit.author.login if commit.author else 'Unknown',
                        'date': commit.commit.author.date if commit.commit.author else None,
                        'message': commit.commit.message,
                        'stats': commit.stats if hasattr(commit, 'stats') else None
                    })
                
                # ê¸°ì—¬ì ë¶„ì„
                author_counts = Counter(authors)
                analysis['contributors'] = {
                    'total_contributors': len(set(authors)),
                    'top_contributors': dict(author_counts.most_common(5)),
                    'commit_distribution': dict(author_counts)
                }
                
                # ì‹œê°„ íŒ¨í„´ ë¶„ì„
                if commit_times:
                    hours = [t.hour for t in commit_times if t]
                    days = [t.strftime('%A') for t in commit_times if t]
                    
                    analysis['commit_patterns'] = {
                        'hourly_distribution': dict(Counter(hours)),
                        'daily_distribution': dict(Counter(days)),
                        'most_active_hour': max(set(hours), key=hours.count) if hours else None,
                        'most_active_day': max(set(days), key=days.count) if days else None
                    }
                
                # ìµœê·¼ í™œë™
                analysis['recent_activity'] = {
                    'commits_last_30_days': len(commits),
                    'avg_commits_per_day': len(commits) / days_back,
                    'last_commit_date': commits[0].commit.author.date if commits[0].commit.author else None
                }
            
            # ì–¸ì–´ ì •ë³´
            try:
                languages = repo.get_languages()
                total_bytes = sum(languages.values())
                analysis['languages'] = {
                    lang: {
                        'bytes': bytes_count,
                        'percentage': (bytes_count / total_bytes) * 100 if total_bytes > 0 else 0
                    }
                    for lang, bytes_count in languages.items()
                }
            except:
                analysis['languages'] = {}
            
            # PR ë° ì´ìŠˆ ì •ë³´ (ê°„ë‹¨í•œ í†µê³„ë§Œ)
            try:
                recent_prs = list(repo.get_pulls(state='all')[:20])
                recent_issues = list(repo.get_issues(state='all')[:20])
                
                analysis['recent_activity'].update({
                    'open_prs': len([pr for pr in recent_prs if pr.state == 'open']),
                    'closed_prs': len([pr for pr in recent_prs if pr.state == 'closed']),
                    'open_issues': len([issue for issue in recent_issues if issue.state == 'open' and not issue.pull_request]),
                    'closed_issues': len([issue for issue in recent_issues if issue.state == 'closed' and not issue.pull_request])
                })
            except:
                pass
            
            return analysis
        
        except Exception as e:
            logger.error(f"ì €ì¥ì†Œ {repo_name} ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def check_rate_limit(self) -> Dict:
        """API ì†ë„ ì œí•œ í™•ì¸"""
        rate_limit = self.github.get_rate_limit()
        return {
            'remaining': rate_limit.core.remaining,
            'limit': rate_limit.core.limit,
            'reset_time': rate_limit.core.reset
        }

def create_realtime_dashboard():
    """ì‹¤ì‹œê°„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    st.set_page_config(
        page_title="ì‹¤ì‹œê°„ GitHub ì €ì¥ì†Œ ë¶„ì„ê¸°",
        page_icon="ğŸ”",
        layout="wide"
    )
    
    st.title("ğŸ” ì‹¤ì‹œê°„ GitHub ì €ì¥ì†Œ ë¶„ì„ê¸°")
    st.markdown("GitHub ì €ì¥ì†Œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")
    
    # GitHub í† í° í™•ì¸
    github_token = os.getenv("GITHUB_TOKEN")
    if not github_token:
        st.error("GitHub í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— GITHUB_TOKENì„ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = RealtimeGitHubAnalyzer(github_token)
    
    analyzer = st.session_state.analyzer
    
    # API ì†ë„ ì œí•œ ì •ë³´ í‘œì‹œ
    rate_limit_info = analyzer.check_rate_limit()
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("API ìš”ì²­ ë‚¨ìŒ", rate_limit_info['remaining'])
    with col2:
        st.metric("API ì œí•œ", rate_limit_info['limit'])
    with col3:
        reset_time = rate_limit_info['reset_time'].strftime('%H:%M:%S')
        st.metric("ë¦¬ì…‹ ì‹œê°„", reset_time)
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ì €ì¥ì†Œ ê²€ìƒ‰", "ì‹¤ì‹œê°„ ë¶„ì„", "ë¹„êµ ë¶„ì„"])
    
    with tab1:
        st.header("GitHub ì €ì¥ì†Œ ê²€ìƒ‰")
        
        # ê²€ìƒ‰ í¼
        with st.form("search_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                search_query = st.text_input("ê²€ìƒ‰ì–´", placeholder="ì˜ˆ: machine learning, web framework")
                language = st.selectbox("ì–¸ì–´ í•„í„°", 
                                      ["ëª¨ë“  ì–¸ì–´", "Python", "JavaScript", "Java", "TypeScript", 
                                       "C++", "C#", "Go", "Rust", "Swift", "Kotlin"])
            
            with col2:
                min_stars = st.number_input("ìµœì†Œ ìŠ¤íƒ€ ìˆ˜", min_value=0, value=100)
                max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜", min_value=5, max_value=50, value=10)
            
            search_button = st.form_submit_button("ê²€ìƒ‰", type="primary")
        
        # ê²€ìƒ‰ ì‹¤í–‰
        if search_button and search_query:
            with st.spinner("ì €ì¥ì†Œ ê²€ìƒ‰ ì¤‘..."):
                lang_filter = None if language == "ëª¨ë“  ì–¸ì–´" else language
                results = analyzer.search_repositories(
                    query=search_query,
                    language=lang_filter,
                    min_stars=min_stars,
                    max_results=max_results
                )
            
            if results:
                st.success(f"{len(results)}ê°œì˜ ì €ì¥ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ê²°ê³¼ í‘œì‹œ
                for i, repo in enumerate(results):
                    with st.expander(f"â­ {repo['stars']} | {repo['full_name']} ({repo['language']})"):
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            st.markdown(f"**ì„¤ëª…:** {repo['description']}")
                            st.markdown(f"**ìƒì„±ì¼:** {repo['created_at'].strftime('%Y-%m-%d')}")
                            st.markdown(f"**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** {repo['updated_at'].strftime('%Y-%m-%d')}")
                            st.markdown(f"**ë§í¬:** [GitHubì—ì„œ ë³´ê¸°]({repo['url']})")
                        
                        with col2:
                            st.metric("â­ Stars", f"{repo['stars']:,}")
                            st.metric("ğŸ´ Forks", f"{repo['forks']:,}")
                            
                            # ë¹ ë¥¸ ë¶„ì„ ë²„íŠ¼
                            if st.button(f"ë¶„ì„í•˜ê¸°", key=f"analyze_{i}"):
                                st.session_state[f"analyze_repo_{i}"] = repo['full_name']
                                st.rerun()
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
    
    with tab2:
        st.header("ì‹¤ì‹œê°„ ì €ì¥ì†Œ ë¶„ì„")
        
        # ì§ì ‘ ì €ì¥ì†Œ ì…ë ¥
        repo_input = st.text_input("ì €ì¥ì†Œ ì…ë ¥", placeholder="owner/repository (ì˜ˆ: facebook/react)")
        days_back = st.slider("ë¶„ì„ ê¸°ê°„ (ì¼)", min_value=7, max_value=90, value=30)
        
        # ê²€ìƒ‰ íƒ­ì—ì„œ ì„ íƒëœ ì €ì¥ì†Œ í™•ì¸
        selected_repo = None
        for i in range(50):  # ìµœëŒ€ 50ê°œ ê²°ê³¼ í™•ì¸
            if f"analyze_repo_{i}" in st.session_state:
                selected_repo = st.session_state[f"analyze_repo_{i}"]
                del st.session_state[f"analyze_repo_{i}"]
                break
        
        repo_to_analyze = selected_repo or repo_input
        
        if repo_to_analyze:
            analyze_button = st.button("ë¶„ì„ ì‹œì‘", type="primary")
            
            if analyze_button:
                with st.spinner(f"{repo_to_analyze} ë¶„ì„ ì¤‘..."):
                    analysis = analyzer.quick_analyze_repository(repo_to_analyze, days_back)
                
                if analysis:
                    display_analysis_results(analysis)
                else:
                    st.error("ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì €ì¥ì†Œ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    with tab3:
        st.header("ì €ì¥ì†Œ ë¹„êµ ë¶„ì„")
        st.info("ì—¬ëŸ¬ ì €ì¥ì†Œë¥¼ ë¹„êµ ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤. (ê°œë°œ ì˜ˆì •)")
        
        # ë¹„êµí•  ì €ì¥ì†Œ ì…ë ¥
        col1, col2 = st.columns(2)
        
        with col1:
            repo1 = st.text_input("ì €ì¥ì†Œ 1", placeholder="owner/repository")
        
        with col2:
            repo2 = st.text_input("ì €ì¥ì†Œ 2", placeholder="owner/repository")
        
        if st.button("ë¹„êµ ë¶„ì„"):
            if repo1 and repo2:
                st.info("ë¹„êµ ë¶„ì„ ê¸°ëŠ¥ì€ ê³§ ì¶”ê°€ë  ì˜ˆì •ì…ë‹ˆë‹¤!")
            else:
                st.warning("ë‘ ì €ì¥ì†Œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def display_analysis_results(analysis: Dict):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    repo_info = analysis['repo_info']
    
    # ì €ì¥ì†Œ ê¸°ë³¸ ì •ë³´
    st.markdown(f"## ğŸ“Š {repo_info['full_name']} ë¶„ì„ ê²°ê³¼")
    st.markdown(f"**ì„¤ëª…:** {repo_info['description'] or 'ì„¤ëª… ì—†ìŒ'}")
    
    # ê¸°ë³¸ ë©”íŠ¸ë¦­
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("â­ Stars", f"{repo_info['stars']:,}")
    with col2:
        st.metric("ğŸ´ Forks", f"{repo_info['forks']:,}")
    with col3:
        st.metric("ğŸ“ Open Issues", f"{repo_info['open_issues']:,}")
    with col4:
        st.metric("ğŸ’¾ Size (KB)", f"{repo_info['size']:,}")
    
    # ìµœê·¼ í™œë™
    st.markdown("### ğŸ“ˆ ìµœê·¼ í™œë™")
    recent = analysis['recent_activity']
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("ìµœê·¼ 30ì¼ ì»¤ë°‹", recent.get('commits_last_30_days', 0))
    with col2:
        st.metric("ì¼í‰ê·  ì»¤ë°‹", f"{recent.get('avg_commits_per_day', 0):.1f}")
    with col3:
        if recent.get('last_commit_date'):
            days_ago = (datetime.now() - recent['last_commit_date'].replace(tzinfo=None)).days
            st.metric("ë§ˆì§€ë§‰ ì»¤ë°‹", f"{days_ago}ì¼ ì „")
    
    # ì–¸ì–´ ë¶„í¬
    if analysis['languages']:
        st.markdown("### ğŸ’» ì–¸ì–´ ë¶„í¬")
        
        lang_data = []
        for lang, info in analysis['languages'].items():
            lang_data.append({
                'language': lang,
                'percentage': info['percentage']
            })
        
        lang_df = pd.DataFrame(lang_data)
        
        fig = px.pie(lang_df, values='percentage', names='language', 
                    title="ì–¸ì–´ë³„ ì½”ë“œ ë¶„í¬")
        st.plotly_chart(fig, use_container_width=True)
    
    # ê¸°ì—¬ì ì •ë³´
    if analysis['contributors']:
        st.markdown("### ğŸ‘¥ ì£¼ìš” ê¸°ì—¬ì")
        contributors = analysis['contributors']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ì´ ê¸°ì—¬ì ìˆ˜", contributors['total_contributors'])
            
            # ìƒìœ„ ê¸°ì—¬ì
            if contributors['top_contributors']:
                top_contrib_df = pd.DataFrame([
                    {'ê¸°ì—¬ì': k, 'ì»¤ë°‹ ìˆ˜': v} 
                    for k, v in contributors['top_contributors'].items()
                ])
                st.dataframe(top_contrib_df, use_container_width=True)
        
        with col2:
            # ê¸°ì—¬ìë³„ ì»¤ë°‹ ìˆ˜ ì°¨íŠ¸
            if contributors['top_contributors']:
                fig = px.bar(
                    x=list(contributors['top_contributors'].keys()),
                    y=list(contributors['top_contributors'].values()),
                    title="ìƒìœ„ ê¸°ì—¬ìë³„ ì»¤ë°‹ ìˆ˜"
                )
                fig.update_layout(xaxis_title="ê¸°ì—¬ì", yaxis_title="ì»¤ë°‹ ìˆ˜")
                st.plotly_chart(fig, use_container_width=True)
    
    # ì»¤ë°‹ íŒ¨í„´
    if analysis['commit_patterns']:
        st.markdown("### â° ì»¤ë°‹ íŒ¨í„´")
        patterns = analysis['commit_patterns']
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ì‹œê°„ëŒ€ë³„ ë¶„í¬
            if patterns.get('hourly_distribution'):
                hourly_data = patterns['hourly_distribution']
                hours = list(hourly_data.keys())
                counts = list(hourly_data.values())
                
                fig = px.bar(x=hours, y=counts, title="ì‹œê°„ëŒ€ë³„ ì»¤ë°‹ ë¶„í¬")
                fig.update_layout(xaxis_title="ì‹œê°„", yaxis_title="ì»¤ë°‹ ìˆ˜")
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # ìš”ì¼ë³„ ë¶„í¬
            if patterns.get('daily_distribution'):
                daily_data = patterns['daily_distribution']
                days = list(daily_data.keys())
                counts = list(daily_data.values())
                
                fig = px.bar(x=days, y=counts, title="ìš”ì¼ë³„ ì»¤ë°‹ ë¶„í¬")
                fig.update_layout(xaxis_title="ìš”ì¼", yaxis_title="ì»¤ë°‹ ìˆ˜")
                st.plotly_chart(fig, use_container_width=True)
        
        # ê°€ì¥ í™œë°œí•œ ì‹œê°„/ìš”ì¼
        if patterns.get('most_active_hour') is not None and patterns.get('most_active_day'):
            st.info(f"ğŸ”¥ ê°€ì¥ í™œë°œí•œ ì‹œê°„: {patterns['most_active_hour']}ì‹œ, ê°€ì¥ í™œë°œí•œ ìš”ì¼: {patterns['most_active_day']}")

if __name__ == "__main__":
    create_realtime_dashboard()